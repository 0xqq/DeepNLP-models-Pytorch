{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GloVe: Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture3.pdf\n",
    "* https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_vocab_vector(vocab, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if w in word2index.keys() else word2index[\"<UNK>\"], vocab))\n",
    "    tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else  Variable(torch.LongTensor(idxs))\n",
    "    return tensor\n",
    "\n",
    "def make_input_vector(input,word2index):\n",
    "    tensor = Variable(torch.LongTensor([word2index[input]]) if input in word2index.keys() else torch.LongTensor([word2index[\"<UNK>\"]]))\n",
    "    if USE_CUDA:\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "#make_input_vector(train_data[0][1], word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus : CoNLL 2000 corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have gutenberg corpus, you can download it first using nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wget http://mattmahoney.net/dc/text8.zip -P /tmp<br>\n",
    "unzip text8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = list(itertools.islice(Text8Corpus('../dataset/corpus/text8'),None))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.txt', 'test.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2000.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = list(nltk.corpus.conll2000.sents('train.txt'))[:1000]\n",
    "corpus = [[word.lower() for word in sent] for sent in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7792"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2index={}\n",
    "for vo in vocab:\n",
    "    if vo not in word2index.keys():\n",
    "        word2index[vo]=len(word2index)\n",
    "        \n",
    "index2word={v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "windows =  flatten([list(nltk.ngrams(['<DUMMY>']*WINDOW_SIZE+c+['<DUMMY>']*WINDOW_SIZE,WINDOW_SIZE*2+1)) for c in corpus])\n",
    "\n",
    "window_data = []\n",
    "\n",
    "for window in windows:\n",
    "    for i in range(WINDOW_SIZE*2+1):\n",
    "        if i==WINDOW_SIZE or window[i]=='<DUMMY>': continue\n",
    "        window_data.append((window[WINDOW_SIZE],window[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Co-occurence Matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighting(w_i,w_j):\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i,w_j)]\n",
    "    except:\n",
    "        x_ij = 1\n",
    "        \n",
    "    x_max = 100 #100 # fixed in paper\n",
    "    alpha = 0.75\n",
    "    \n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha\n",
    "    else:\n",
    "        result = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_i = Counter(flatten(corpus)) # X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ik_window_5 = Counter(window_data) # Co-occurece in window size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ik={}\n",
    "weighting_dic={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of model complexity, It is important to determine whether a tighter bound can be placed on the number of nonzero elements of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bigram in combinations_with_replacement(vocab, 2):\n",
    "    if bigram in X_ik_window_5.keys(): # nonzero elements\n",
    "        co_occer = X_ik_window_5[bigram]\n",
    "        X_ik[bigram]=co_occer+1 # log(Xik) -> log(Xik+1) to prevent divergence\n",
    "        X_ik[(bigram[1],bigram[0])]=co_occer+1\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    weighting_dic[bigram] = weighting(bigram[0],bigram[1])\n",
    "    weighting_dic[(bigram[1],bigram[0])] = weighting(bigram[1],bigram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shall', 'the')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test = random.choice(window_data)\n",
    "print(test)\n",
    "try:\n",
    "    print(X_ik[(test[0],test[1])]==X_ik[(test[1],test[0])])\n",
    "except:\n",
    "    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 3835\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      " 4729\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      "1.00000e-02 *\n",
      "  5.3183\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "u_p=[] # center vec\n",
    "v_p=[] # context vec\n",
    "co_p=[] # log(x_ij)\n",
    "weight_p=[] # f(x_ij)\n",
    "\n",
    "for pair in window_data: # 실은 여기서 vocab x vocab이어야 하지만..\n",
    "    temp = make_input_vector(pair[0],word2index)\n",
    "    u_p.append(temp.view(1,-1))\n",
    "    temp = make_input_vector(pair[1],word2index)\n",
    "    v_p.append(temp.view(1,-1))\n",
    "    \n",
    "    try:\n",
    "        cooc = X_ik[pair]\n",
    "    except:\n",
    "        cooc = 1\n",
    "    \n",
    "    temp = torch.log(Variable(torch.Tensor([cooc]))).cuda() if USE_CUDA else torch.log(Variable(torch.Tensor([cooc])))\n",
    "    co_p.append(temp.view(1,-1))\n",
    "    temp = Variable(torch.Tensor([weighting_dic[pair]])).cuda() if USE_CUDA else Variable(torch.Tensor([weighting_dic[pair]]))\n",
    "    weight_p.append(temp.view(1,-1))\n",
    "                                  \n",
    "train_data = list(zip(u_p,v_p,co_p,weight_p))\n",
    "del u_p\n",
    "del v_p\n",
    "del co_p\n",
    "del weight_p\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,projection_dim):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, projection_dim) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, projection_dim) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size,1)\n",
    "        self.u_bias = nn.Embedding(vocab_size,1)\n",
    "        \n",
    "        initrange = (2.0 / (vocab_size+projection_dim))**0.5 # Xavier init\n",
    "        self.embedding_v.weight.data.uniform_(-initrange, initrange) # init\n",
    "        self.embedding_u.weight.data.uniform_(-initrange, initrange) # init\n",
    "        self.v_bias.weight.data.uniform_(-initrange, initrange) # init\n",
    "        self.u_bias.weight.data.uniform_(-initrange, initrange) # init\n",
    "        \n",
    "    def forward(self, inputs,targets,coocs,weights):\n",
    "        center_embeds = self.embedding_v(inputs) # B x 1 x D\n",
    "        context_embeds = self.embedding_u(targets) # B x 1 x D\n",
    "        \n",
    "        center_bias = self.v_bias(inputs).squeeze(1)\n",
    "        context_bias = self.u_bias(targets).squeeze(1)\n",
    "        \n",
    "        inner_product = center_embeds.bmm(context_embeds.transpose(1,2)).squeeze(1) # Bx1\n",
    "        \n",
    "        loss = weights*torch.pow(inner_product +center_bias + context_bias - coocs,2)\n",
    "        \n",
    "        return torch.sum(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        v_embeds = self.embedding_v(inputs) # B x 1 x D\n",
    "        u_embeds = self.embedding_u(inputs) # B x 1 x D\n",
    "                \n",
    "        return v_embeds+u_embeds # final embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECTION = 50 # Embedding size\n",
    "BATCH_SIZE = 256\n",
    "STEP_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "model = GloVe(len(word2index),PROJECTION)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0, mean_loss : 99.30\n",
      "Step : 10, mean_loss : 1.57\n",
      "Step : 20, mean_loss : 0.19\n",
      "Step : 30, mean_loss : 0.14\n",
      "Step : 40, mean_loss : 0.12\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP_SIZE):\n",
    "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        \n",
    "        inputs, targets, coocs, weights = zip(*batch)\n",
    "        \n",
    "        inputs = torch.cat(inputs) # B x 1\n",
    "        targets = torch.cat(targets) # B x 1\n",
    "        coocs = torch.cat(coocs)\n",
    "        weights = torch.cat(weights)\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss = model(inputs,targets,coocs,weights)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        losses.append(loss.data.cpu().numpy()[0] if USE_CUDA else loss.data.numpy()[0])\n",
    "    if step % 10==0:\n",
    "        print(\"Step : %d, mean_loss : %.02f\" % (step,np.mean(losses)))\n",
    "        losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean, cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_similarity(target,vocab):\n",
    "    if USE_CUDA:\n",
    "        target_V = model.prediction(make_input_vector(target,word2index)).data.cpu().numpy()\n",
    "    else:\n",
    "        target_V = model.prediction(make_input_vector(target,word2index)).data.numpy()\n",
    "    similarities=[]\n",
    "    for i in range(len(vocab)):\n",
    "        if vocab[i] == target: continue\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            vector = model.prediction(make_input_vector(list(vocab)[i],word2index)).data.cpu().numpy()\n",
    "        else:\n",
    "            vector = model.prediction(make_input_vector(list(vocab)[i],word2index)).data.numpy()\n",
    "        #similarity.append([vocabs[i],np.dot(target_V,vector.T)[0][0]])\n",
    "        similarities.append([vocab[i],cosine(target_V,vector)-1])\n",
    "     \n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = random.choice(list(vocab))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['historic', 0.52985090571123172],\n",
       " ['institutions', 0.51528080054999559],\n",
       " ['oman', 0.51192182815654541],\n",
       " ['qatar', 0.49771550991169367],\n",
       " ['athletics', 0.49280027896029033],\n",
       " ['mountainous', 0.48496822698777575],\n",
       " ['univ', 0.47659709787058979],\n",
       " ['behaved', 0.47069340673768933],\n",
       " ['statistical', 0.46401518878823866],\n",
       " ['heretics', 0.46206135905113332]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(test,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이게 제대로 짠건지 검증을 못하겠네... 어케하지?\n",
    "* model complexity 부분 좀 더 보기... \n",
    "* CoNLL-2003으로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cp = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp.fit(corpus, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69359"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cp.matrix.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = Glove(no_components=50, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "glove.fit(cp.matrix, epochs=30, no_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove.add_dictionary(cp.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.8470', 0.71143872269798525),\n",
       " ('break-up', 0.70466115535936069),\n",
       " ('mature', 0.69045816991044795),\n",
       " ('11th', 0.6800949534611328),\n",
       " ('players', 0.67941097775441706),\n",
       " ('perspective', 0.67904147363693679),\n",
       " ('naturally', 0.67851819839217864),\n",
       " ('quotes', 0.67562121808072884),\n",
       " ('third-largest', 0.67527938644901375)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
