{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Machine translation and advanced recurrent LSTMs and GRUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture9.pdf\n",
    "* https://arxiv.org/pdf/1406.1078.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "from copy import deepcopy\n",
    "import os\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to_batch(batch,x_to_ix,y_to_ix):\n",
    "    x,y = list(zip(*batch))\n",
    "    max_x = max([s.size(1) for s in x])\n",
    "    max_y = max([s.size(1) for s in y])\n",
    "    x_p,y_p=[],[]\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1)<max_x:\n",
    "            x_p.append(torch.cat([x[i],Variable(LongTensor([x_to_ix['<PAD>']]*(max_x-x[i].size(1)))).view(1,-1)],1))\n",
    "        else:\n",
    "            x_p.append(x[i])\n",
    "        if y[i].size(1)<max_y:\n",
    "            y_p.append(torch.cat([y[i],Variable(LongTensor([y_to_ix['<PAD>']]*(max_y-y[i].size(1)))).view(1,-1)],1))\n",
    "        else:\n",
    "            y_p.append(y[i])\n",
    "    return torch.cat(x_p),torch.cat(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation data is too large to process using my computer. And It takes too much time with naive softmax for large vocab. So I use smallchat data collecting from <a href=\"https://dbd-challenge.github.io/dbdc3/datasets\">here</a>. Maybe we'll use wmt16 data later with attention and sampled softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source_corpus = open('../dataset/wmt16_de_en/train.tok.en','r',encoding='utf-8').readlines()\n",
    "# target_corpus = open('../dataset/wmt16_de_en/train.tok.de','r',encoding='utf-8.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tknz = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('../dataset/smallchat.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_corpus = [d.split('\\t')[0].lower() for d in data]\n",
    "target_corpus =  [d.split('\\t')[1][:-1].lower() for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4172\n"
     ]
    }
   ],
   "source": [
    "print(len(source_corpus)==len(target_corpus))\n",
    "print(len(source_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_r,y_r=[],[] # raw\n",
    "\n",
    "for parallel in zip(source_corpus,target_corpus):\n",
    "    if parallel[1]=='\\n':continue\n",
    "    so,ta = parallel[0], parallel[1]\n",
    "    if so.strip()==\"\" or ta.strip()==\"\": continue\n",
    "    X_r.append(tknz.tokenize(so))\n",
    "    y_r.append(tknz.tokenize(ta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_LIMIT = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In paper, they limit the source and target vocabulary to the most frequent 15,000 words. <br>\n",
    "There are some problems of softmax operation's complexity to large target. You should determine this hyper-param in practice. \n",
    "We'll deal with this large vocab problem later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source_vocab_count = Counter(flatten(X_r))\n",
    "# source_vocab, _ = list(zip(*source_vocab_count.most_common()[:VOCAB_LIMIT]))\n",
    "\n",
    "# target_vocab_count = Counter(flatten(y_r))\n",
    "# target_vocab, _  = list(zip(*target_vocab_count.most_common()[:VOCAB_LIMIT]))\n",
    "# print(len(source_vocab),len(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source2index = {'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "# for vo in source_vocab:\n",
    "#     source2index[vo]=len(source2index)\n",
    "# index2source = {v:k for k,v in source2index.items()}\n",
    "\n",
    "# target2index = {'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "# for vo in target_vocab:\n",
    "#     target2index[vo]=len(target2index)\n",
    "# index2target = {v:k for k,v in target2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_count = Counter(flatten(X_r)+flatten(y_r))\n",
    "vocab, _ = list(zip(*vocab_count.most_common()[:VOCAB_LIMIT]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4014"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index={'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "for vo in vocab:\n",
    "    if vo not in word2index.keys():\n",
    "        word2index[vo]=len(word2index)\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 12 ms, total: 208 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_p,y_p=[],[]\n",
    "\n",
    "temp = list(zip(X_r,y_r))\n",
    "random.shuffle(temp)\n",
    "train_p = temp[:int(len(temp)*0.9)]\n",
    "test_data = temp[int(len(temp)*0.9):]\n",
    "\n",
    "for so,ta in train_p:\n",
    "    X_p.append(prepare_sequence(so,word2index).view(1,-1))\n",
    "    y_p.append(prepare_sequence(ta,word2index).view(1,-1))\n",
    "    \n",
    "train_data = list(zip(X_p,y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size,hidden_size, n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
    "    \n",
    "    def init_hidden(self,inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers*2,inputs.size(0),self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "#         self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "#         self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "    \n",
    "    def forward(self, inputs, input_masking=None):\n",
    "        \"\"\"\n",
    "        inputs : B,T (LongTensor)\n",
    "        input_masking : B,T (ByteTensor) if you don't use zero-padding, leave it at that\n",
    "        \"\"\"\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        real_context=[]\n",
    "        \n",
    "        if type(input_masking)==torch.autograd.variable.Variable:\n",
    "            for i,o in enumerate(output): # B,T,D\n",
    "                real_length = input_masking[i].data.tolist().count(0) # real length\n",
    "                real_context.append(o[real_length-1])\n",
    "            hidden = torch.cat(real_context).view(inputs.size(0),-1).unsqueeze(1)\n",
    "        else:\n",
    "            hidden = torch.cat(hidden,1).unsqueeze(1)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1,dropout_p=0.3):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Define the layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.gru = nn.GRU(embedding_size+hidden_size, hidden_size, n_layers,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size*2, input_size)\n",
    "    \n",
    "    def init_hidden(self,inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers,inputs.size(0),self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "#         self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "#         self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "    \n",
    "    def forward(self, inputs, context,max_length,training=False):\n",
    "        \"\"\"\n",
    "        inputs : B,1 (LongTensor, START SYMBOL)\n",
    "        context : B,1,H (FloatTensor, Last encoder hidden state)\n",
    "        max_length : int, max length to decode\n",
    "        training : bool, this is because adapt dropout only training step.\n",
    "        \"\"\"\n",
    "        # Get the embedding of the current input word\n",
    "        embedded = self.embedding(inputs)\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        if training:\n",
    "            embedded = self.dropout(embedded)\n",
    "        \n",
    "        decode=[]\n",
    "        # Apply GRU to the output so far\n",
    "        for i in range(max_length):\n",
    "\n",
    "            _, hidden = self.gru(torch.cat((embedded,context),2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "            concated = torch.cat((hidden,context.transpose(0,1)),2) # y_t = g(h_t,y_{t-1},c)\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decode.append(softmaxed)\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            if training:\n",
    "                embedded = self.dropout(embedded)\n",
    "            \n",
    "        #  column-wise concat, reshape!!\n",
    "        scores = torch.cat(decode,1)\n",
    "        return scores.view(inputs.size(0)*max_length,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes for a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP=100\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZE = 128\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE,2)\n",
    "decoder = Decoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE*2)\n",
    "encoder.init_weight()\n",
    "decoder.init_weight()\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(),lr=LR)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100] mean_loss : 6.03\n",
      "[10/100] mean_loss : 4.33\n",
      "[20/100] mean_loss : 3.19\n",
      "[30/100] mean_loss : 2.37\n",
      "[40/100] mean_loss : 1.73\n",
      "[50/100] mean_loss : 1.25\n",
      "[60/100] mean_loss : 0.93\n",
      "[70/100] mean_loss : 0.74\n",
      "[80/100] mean_loss : 0.62\n",
      "[90/100] mean_loss : 0.55\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        inputs,targets = pad_to_batch(batch,word2index,word2index)\n",
    "        \n",
    "        input_mask = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data))),volatile=False) for t in inputs]).view(inputs.size(0),-1)\n",
    "        start_decode = Variable(LongTensor([[word2index['<SOS>']]*targets.size(0)])).transpose(0,1)\n",
    "        \n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        output, hidden_c = encoder(inputs,input_mask)\n",
    "        \n",
    "        preds = decoder(start_decode,hidden_c,targets.size(1),True)\n",
    "                                \n",
    "        loss = loss_function(preds,targets.view(-1))\n",
    "        losses.append(loss.data.cpu().numpy()[0] if USE_CUDA else loss.data.numpy()[0] )\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 0.5) # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 0.5) # gradient clipping\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "    \n",
    "    if step % 10==0:\n",
    "        print(\"[%d/%d] mean_loss : %0.2f\" %(step,STEP,np.mean(losses)))\n",
    "        torch.save(decoder.state_dict(),os.path.join('../','decoder.pkl'))\n",
    "        torch.save(encoder.state_dict(),os.path.join('../', 'encoder.pkl'))\n",
    "        losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "USER : hi\n",
      "BOT : i can t know what i don talking about .\n",
      "do you know kimchi?\n",
      "USER : do you know kimchi?\n",
      "BOT : hell ! ! ! the the kimchi !! victoria !\n",
      "do you know Jisung park?\n",
      "USER : do you know Jisung park?\n",
      "BOT : yes . i idea to idea ? about idea ?\n",
      "hmm\n",
      "USER : hmm\n",
      "BOT : it is a matter . i just 't saying .\n",
      "what is your name\n",
      "USER : what is your name\n",
      "BOT : what me t understand :( . i me to discuss\n",
      "fuck you\n",
      "USER : fuck you\n",
      "BOT : yes are are name ? are are are about discuss\n",
      "hell\n",
      "USER : hell\n",
      "BOT : second , go thermodynamics ! the vain , of .\n",
      "you stupid\n",
      "USER : you stupid\n",
      "BOT : i don t know what . i would like .\n",
      "have a good night\n",
      "USER : have a good night\n",
      "BOT : how about we to something to both . about about\n",
      "fuck..\n",
      "USER : fuck..\n",
      "BOT : yeah . i about . your . about . .\n",
      "are you chatbot?\n",
      "USER : are you chatbot?\n",
      "BOT : no ,,!! i 'm... . they by students . i\n",
      "mm\n",
      "USER : mm\n",
      "BOT : you you make the first to your . the iron\n",
      "bye\n",
      "USER : bye\n",
      "BOT : here , ! the ! , . , . ,\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    try:\n",
    "        test = input()\n",
    "        input_ = prepare_sequence(tknz.tokenize(test.lower()),word2index).view(1,-1)\n",
    "        input_mask = Variable(ByteTensor(tuple(map(lambda s: s ==0, input_[0].data)))).view(1,-1)\n",
    "        start_decode = Variable(LongTensor([[word2index['<SOS>']]*1])).transpose(0,1)\n",
    "        o, hidden_c = encoder(input_,input_mask)\n",
    "        pred = decoder(start_decode,hidden_c,10)\n",
    "        pred = pred.max(1)[1].data.cpu().tolist() if USE_CUDA else pred.max(1)[1].data.tolist()\n",
    "\n",
    "        print('USER : '+ test)\n",
    "        # print(' '.join(test[1]))\n",
    "        print('BOT : '+' '.join([index2word[t] for t in pred])) \n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because of noisy data, It is hard to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
