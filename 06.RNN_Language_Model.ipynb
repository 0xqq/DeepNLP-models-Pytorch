{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Recurrent Neural Networks and Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture8.pdf\n",
    "* https://arxiv.org/pdf/1504.00941.pdf\n",
    "* https://arxiv.org/pdf/1609.07843.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "from copy import deepcopy\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to_batch(batch):\n",
    "    x,y = list(zip(*batch))\n",
    "    max_x = max([s.size(1) for s in x])\n",
    "    max_y = max([s.size(1) for s in y])\n",
    "    x_p,y_p=[],[]\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1)<max_x:\n",
    "            x_p.append(torch.cat([x[i],Variable(LongTensor([word2index['<PAD>']]*(max_x-x[i].size(1)))).view(1,-1)],1))\n",
    "        else:\n",
    "            x_p.append(x[i])\n",
    "        if y[i].size(1)<max_y:\n",
    "            y_p.append(torch.cat([y[i],Variable(LongTensor([word2index['<PAD>']]*(max_y-y[i].size(1)))).view(1,-1)],1))\n",
    "        else:\n",
    "            y_p.append(y[i])\n",
    "    return list(zip(x_p,y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if w in to_index.keys() else to_index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = list(nltk.corpus.brown.sents())\n",
    "corpus = [[word.lower() for word in sent] for sent in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths = Counter([len(s) for s in corpus])\n",
    "np.mean(flatten([[key]*count for key, count in seq_lengths.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [sent for sent in corpus if len(sent)<=20 and len(sent)>1] # for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index={'<PAD>':0,'<UNK>':1}\n",
    "for vo in vocab:\n",
    "    if vo not in word2index.keys():\n",
    "        word2index[vo]=len(word2index)\n",
    "        \n",
    "index2word={v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_p,y_p = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sent in corpus:\n",
    "    X_p.append(prepare_sequence(sent[:-1],word2index).view(1,-1))\n",
    "    y_p.append(prepare_sequence(sent[1:],word2index).view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_p = list(zip(X_p,y_p))\n",
    "random.shuffle(data_p)\n",
    "train_data = data_p[:int(len(data_p)*0.9)]\n",
    "dev_data = data_p[int(len(data_p)*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module): \n",
    "    def __init__(self,vocab_size,embedding_size,hidden_size,num_layers=1):\n",
    "\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size,hidden_size,num_layers,nonlinearity='relu',batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size,vocab_size)\n",
    "        \n",
    "        self.init_rnn() # IRNN\n",
    "        self.init_embed()\n",
    "        \n",
    "    def init_embed(self):\n",
    "        self.embed.weight = nn.init.xavier_uniform(self.embed.weight)\n",
    "    \n",
    "    def init_rnn(self):\n",
    "        self.rnn.weight_hh_l0 = nn.init.eye(self.rnn.weight_hh_l0)\n",
    "        self.rnn.weight_ih_l0 = nn.init.eye(self.rnn.weight_ih_l0)\n",
    "        self.rnn.bias_hh_l0.data.fill_(0)\n",
    "        self.rnn.bias_ih_l0.data.fill_(0)\n",
    "        \n",
    "    def init_hidden(self,inputs):\n",
    "        return Variable(FloatTensor(self.num_layers,inputs.size(0),self.hidden_size))\n",
    "        \n",
    "    def forward(self, inputs): \n",
    "        hidden = self.init_hidden(inputs)\n",
    "        embeds = self.embed(inputs) # BxWxD\n",
    "        out,hidden = self.rnn(embeds,hidden)\n",
    "        return F.log_softmax(self.linear(out.contiguous().view(out.size(0)*out.size(1),-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes for a while. And It sometimes explodes its gradient because of 'relu'. I reference <a href=\"https://arxiv.org/pdf/1504.00941.pdf\">this paper</a> about IRNN. I don't know why it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE=300\n",
    "HIDDEN_SIZE=512\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 128\n",
    "STEP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(word2index),EMBED_SIZE,HIDDEN_SIZE)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0) # ignore pad\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] mean_loss : 10.26, perplexity : 28490.04\n",
      "[0/10] mean_loss : 7.70, perplexity : 2208.69\n",
      "[0/10] mean_loss : 6.86, perplexity : 954.94\n",
      "[1/10] mean_loss : 6.35, perplexity : 570.95\n",
      "[1/10] mean_loss : 6.37, perplexity : 581.53\n",
      "[1/10] mean_loss : 6.20, perplexity : 491.79\n",
      "[2/10] mean_loss : 5.73, perplexity : 307.51\n",
      "[2/10] mean_loss : 5.74, perplexity : 311.53\n",
      "[2/10] mean_loss : 5.69, perplexity : 294.82\n",
      "[3/10] mean_loss : 5.30, perplexity : 199.91\n",
      "[3/10] mean_loss : 5.30, perplexity : 200.26\n",
      "[3/10] mean_loss : 5.27, perplexity : 195.09\n",
      "[4/10] mean_loss : 4.99, perplexity : 147.40\n",
      "[4/10] mean_loss : 4.91, perplexity : 135.66\n",
      "[4/10] mean_loss : 4.90, perplexity : 134.93\n",
      "[5/10] mean_loss : 4.59, perplexity : 98.18\n",
      "[5/10] mean_loss : 4.55, perplexity : 94.36\n",
      "[5/10] mean_loss : 4.54, perplexity : 93.75\n",
      "[6/10] mean_loss : 4.16, perplexity : 63.95\n",
      "[6/10] mean_loss : 4.17, perplexity : 64.69\n",
      "[6/10] mean_loss : 4.19, perplexity : 66.17\n",
      "[7/10] mean_loss : 3.89, perplexity : 49.12\n",
      "[7/10] mean_loss : 3.80, perplexity : 44.78\n",
      "[7/10] mean_loss : 3.84, perplexity : 46.69\n",
      "[8/10] mean_loss : 3.50, perplexity : 33.07\n",
      "[8/10] mean_loss : 3.46, perplexity : 31.95\n",
      "[8/10] mean_loss : 3.54, perplexity : 34.40\n",
      "[9/10] mean_loss : 3.21, perplexity : 24.66\n",
      "[9/10] mean_loss : 3.17, perplexity : 23.91\n",
      "[9/10] mean_loss : 3.26, perplexity : 26.05\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    for i,batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        batch = pad_to_batch(batch)\n",
    "        x,y = list(zip(*batch))\n",
    "        inputs = torch.cat(x)\n",
    "        targets = torch.cat(y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs)\n",
    "\n",
    "        loss = loss_function(preds,targets.view(-1))\n",
    "        losses.append(loss.data.cpu().numpy()[0] if USE_CUDA else loss.data.numpy()[0] )\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5) # gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if i % 100==0:\n",
    "            print(\"[%d/%d] mean_loss : %0.2f, perplexity : %0.2f\" %(step,STEP,np.mean(losses),np.exp(np.mean(losses))))\n",
    "            losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.4039735099\n"
     ]
    }
   ],
   "source": [
    "for dev in dev_data:\n",
    "    input,target = dev[0],dev[1]\n",
    "    \n",
    "    pred = model(input).max(1)[1].data.cpu().tolist() if USE_CUDA else model(input).max(1)[1].data.tolist() \n",
    "    target = target.data.cpu().tolist() if USE_CUDA else target.data.tolist()\n",
    "    \n",
    "    accuracy+=np.equal(pred,target).sum()\n",
    "    \n",
    "print(accuracy/len(flatten(dev_data))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sent = ' '.join(random.choice(corpus))\n",
    "# test_sent = 'Jane said hi to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if the turn was too tight , a barrel roll would bring them out .'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = prepare_sequence(test_sent[:-1].split(),word2index).view(1,-1)\n",
    "pred = model(input).max(1)[1].data.cpu().tolist() if USE_CUDA else model(input).max(1)[1].data.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you crummy cleared empty , , he man roll would be out . .'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(map(lambda i: index2word[i], pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
